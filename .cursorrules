# Aitomics Library Rules and Guidelines

## Core Concepts

### Callers and Responses
- Always use `$` for creating LLM callers and `_` for utility functions
- Each caller must have a unique ID (either provided or auto-generated)
- Responses maintain a linked list structure for tracing transformations
- Use `Response.create()` for external data integration

### Response Structure
```javascript
{
  output: String | Object,
  caller: Caller,
  input: String | Response,
  generator: generatingType, // INPUT, PROGRAMMATIC, CUSTOM
  root: boolean,
  level: number
}
```

### Comparison Models
- Use `EqualComparisonModel` for exact matches
- Use `DistanceComparisonModel` for similarity-based comparison
- Use `KrippendorffsComparisonModel` for single-label IRR
- Use `CohensComparisonModel` for multi-label IRR

### Utility Functions
- Basic utilities: `_.lowerCase`, `_.upperCase`, `_.stringToJSON`, `_.JSONToString`, `_.extract`
- Analysis utilities: `_.inference`, `_.confidence`
- Custom utilities can be created using `createUtilityAnalysisCaller`

## Best Practices

### Caller Creation
```javascript
// Good: Named caller
const caller = $("Transform text", "unique-name")

// Good: Programmatic caller
const caller = $((input) => input.toUpperCase(), "uppercase-transformer")

// Bad: Unnamed duplicate callers
const caller1 = $("Transform text")
const caller2 = $("Transform text") // Will throw error
```

### Response Handling
```javascript
// Good: Chaining transformations
const result = await _.compose(caller1, caller2).run(input)

// Good: Accessing previous transformations
const prevResult = result.input

// Good: Creating from external data
const response = Response.create({
  output: "External data",
  input: "Original input"
})
```

### Comparison Usage
```javascript
// Good: Basic comparison (single response)
const comparison = result2.compare(result1).run(new EqualComparisonModel())

// Good: Distance-based comparison (single response)
const orderedList = ["very_bad", "bad", "neutral", "good", "very_good"] // Ordered list of possible values
const maxDistance = 1 // Maximum distance for considering values as "close"
const weightFn = (k, l) => {
  if (k === l) return 1;
  const kIndex = orderedList.indexOf(k);
  const lIndex = orderedList.indexOf(l);
  if (kIndex === -1 || lIndex === -1) return 0;
  const dist = Math.abs(kIndex - lIndex);
  return dist <= maxDistance ? 0.5 : 0;
}
const comparison = result2.compare(result1).run(new DistanceComparisonModel(maxDistance, orderedList, weightFn))

// Good: Multi-response comparison with Krippendorff's Alpha (single label)
const reviewer1 = [response1, response3] // First reviewer's responses
const reviewer2 = [response2, response4] // Second reviewer's responses
const possibleLabels = ["positive", "negative", "neutral"] // List of possible labels
const weightFn = (k, l) => k === l ? 1 : 0 // Optional weight function for label agreement
const comparison = ComparisonModel.compareMultiple(
  reviewer1, 
  reviewer2, 
  new KrippendorffsComparisonModel(possibleLabels, weightFn)
)

// Good: Multi-response comparison with Cohen's Kappa (multiple labels)
const reviewer1 = [response1, response3] // First reviewer's responses
const reviewer2 = [response2, response4] // Second reviewer's responses
const valueToCheck = "positive" // The specific value to check for agreement
const comparison = ComparisonModel.compareMultiple(
  reviewer1, 
  reviewer2, 
  new CohensComparisonModel(valueToCheck)
)
```

### Visualization
- Always provide meaningful names for callers
- Use `Response.create()` with custom names for better visualization
- Avoid duplicate caller names
- Consider using `showExampleData` for complex flows

Example:
```javascript
import { generateFlowDiagram } from 'aitomics'

// Create responses with named callers
const caller1 = $("First transformation", "step1")
const caller2 = $("Second transformation", "step2")
const result1 = await caller1.run(input)
const result2 = await caller2.run(input)

// Create another flow with different transformations
const caller3 = $("Alternative transformation", "alt-step1")
const caller4 = $("Final transformation", "alt-step2")
const result3 = await caller3.run(input)
const result4 = await caller4.run(input)

// Generate flow diagram with multiple flows
const { markdown, diagram } = await generateFlowDiagram(
  [
    [result1, result2], // First flow
    [result3, result4]  // Second flow
  ],
  {
    labels: ["Main Flow", "Alternative Flow"], // Labels for each flow path
    showExampleData: true, // Show example data on arrows
    initialInputIndex: 0 // Use first response for example data
  }
)

// Save the diagram
fs.writeFileSync("flow-diagram.svg", diagram)
```

### Configuration
- Use YAML for prompt configuration
- Override LLM settings using `setConfigFromFile` or `setConfigFromObject`
- Default config path: `./src/util/fetch/default_config.yml`

## Configuration Templates

### YAML Configuration
```yaml
# config.yml
model: llama-3.2-3b-instruct  # The model name to use
path: https://127.0.0.1       # The base URL for the LLM API
port: 1234                    # The port number
endpoint: v1/chat/completions # The API endpoint
settings:
  temperature: 0.7            # Controls randomness (0.0 to 1.0)
  max_tokens: -1              # Maximum tokens to generate (-1 for unlimited)
  stream: false               # Whether to stream the response
```

### Object Configuration
```javascript
// config.js
const config = {
    model: "llama-3.2-3b-instruct",
    path: "https://127.0.0.1",
    port: 1234,
    endpoint: "v1/chat/completions",
    settings: {
        temperature: 0.7,
        max_tokens: -1,
        stream: false
    }
}

// Usage
import { setConfigFromObject } from 'aitomics'
setConfigFromObject(config)
```

### Prompt Configuration
```yaml
# prompt.yml
prompt:
    description:
        - multiple lines of prompt content
        - can go here
    values:
        - label: myLabel
          description: a description of the label
        - label: otherLabel
          description: another description of label
    default_value: unknown
```

### Usage in Project
```javascript
// 1. Load configurations
import { setConfigFromFile, parseCategorizationPromptFromYML } from 'aitomics'

// Load LLM settings
setConfigFromFile("./config.yml")

// Load prompt template
const prompt = parseCategorizationPromptFromYML("./prompt.yml")

// 2. Use in callers
const analyzer = $("Analyze text", "analyzer", {
    prompt: prompt,
    // Additional caller-specific settings can be added here
})
```

## Common Patterns

### Basic Transformation Chain
```javascript
const caller1 = $("First transformation", "step1")
const caller2 = $("Second transformation", "step2")
const result = await _.compose(caller1, caller2).run(input)
```

### Analysis Chain
```javascript
const analysis = await _.compose(
  _.inference,
  _.confidence
).run(result)
```

### External Data Integration
```javascript
const externalResponse = Response.create({
  output: externalData,
  input: originalInput,
})
```

### Serialization
```javascript
// Save
writeResponses("responses.json", response)

// Load
const loadedResponses = readResponses("responses.json")
```

## Error Prevention

### Common Mistakes to Avoid
1. Creating duplicate unnamed callers
2. Not providing unique IDs for similar callers
3. Using comparison models with incompatible data types
4. Forgetting to handle async operations with await
5. Not maintaining proper input/output chain in Response.create()

### Validation Rules
1. Caller IDs must be unique within the same functionality
2. Response inputs must match for comparison
3. Utility functions require string or object with output property
4. Visualization requires proper caller naming
5. Serialization requires proper caller linking

## Performance Considerations

### Optimization Tips
1. Use programmatic callers for simple transformations
2. Chain transformations using _.compose
3. Reuse callers when possible
4. Use appropriate comparison models for the data type
5. Consider caching responses for repeated operations

### Memory Management
2. Use serialization for long-term storage
5. Clean up unused callers 

## Project Structure Template

### 1. Setup Phase
```javascript
// 1.1 Configure LLM settings
import { setConfigFromFile } from 'aitomics'
setConfigFromFile("./config.yml")

// 1.2 Define core transformation callers
const textCleaner = $("Clean and normalize text", "text-cleaner")
const sentimentAnalyzer = $("Analyze sentiment", "sentiment-analyzer")
const topicExtractor = $("Extract main topics", "topic-extractor")

// 1.3 Define utility callers
const customAnalyzer = createUtilityAnalysisCaller({
  name: "custom-analysis",
  variable: "analysis",
  prompt: "Your custom analysis prompt"
})

// 1.4 Define analysis chains
const analysisChain = _.compose(
  textCleaner,
  sentimentAnalyzer,
  topicExtractor,
  customAnalyzer
)
```

### 2. Data Loading Phase
```javascript
// 2.1 Load external data as responses
const externalData = Response.create({
  output: "External data content",
  input: "Original source",
})

// 2.2 Create comparison baseline if needed
const baselineResponse = Response.create({
  output: "Baseline data",
  input: "Original source",
  name: "Baseline"
})
```

### 3. Execution Phase
```javascript
// 3.1 Process data with progress updates
console.log("Starting analysis...")
const results = []
for (const item of dataItems) {
  console.log(`Processing item ${item.id}...`)
  const result = await analysisChain.run(item)
  results.push(result)
  
  // 3.2 Optional: Save intermediate results
  writeResponses(`results_${item.id}.json`, result)
  
  // 3.3 Optional: Compare with baseline during processing
  const comparison = result.compare(baselineResponse)
    .run(new DistanceComparisonModel(1, ["low", "medium", "high"]))
  console.log(`Agreement with baseline: ${comparison}`)
}
```

### 4. Finalization Phase
```javascript
// 4.1 Save final results
writeResponses("final_results.json", results)

// 4.2 Generate and save visualization
const { diagram } = await generateFlowDiagram(
  [results], // Main flow
  {
    labels: ["Analysis Flow"],
    showExampleData: true
  }
)
fs.writeFileSync("analysis-flow.svg", diagram)

// 4.3 Optional: Generate comparison report
const finalComparison = ComparisonModel.compareMultiple(
  results,
  baselineResults,
  new KrippendorffsComparisonModel(["positive", "negative", "neutral"])
)
console.log("Final agreement score:", finalComparison)
```

### Best Practices
1. **Setup Phase**
   - Define all callers with meaningful names
   - Group related transformations into chains
   - Configure LLM settings before any execution

2. **Data Loading**
   - Use `Response.create()` for external data
   - Maintain proper input/output chains
   - Name responses meaningfully for visualization

3. **Execution**
   - Provide progress updates
   - Save intermediate results
   - Perform comparisons during processing
   - Handle errors gracefully

4. **Finalization**
   - Save all results
   - Generate visualizations
   - Create comparison reports
   - Clean up temporary data 